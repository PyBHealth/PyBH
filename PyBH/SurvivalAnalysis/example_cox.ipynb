{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194da957",
   "metadata": {},
   "source": [
    "#  Bayesian Piecewise Cox PH (Issue #8)\n",
    " This notebook validates the Piecewise Constant Hazard model implementation using the toy example described in Issue #8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "454f928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import arviz as az\n",
    "\n",
    "# Make sure you have the correct import path\n",
    "from cox import BayesianPiecewiseCoxPH\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84b9f16",
   "metadata": {},
   "source": [
    " ### 1. Toy Example Data\n",
    " Recreating the exact dataset from the issue description:\n",
    " * **Subject 1:** Event at $t=5$, Covariate $x=0$.\n",
    " * **Subject 2:** Censored at $t=8$, Covariate $x=1$.\n",
    " * **Subject 3:** Event at $t=10$, Covariate $x=1$.\n",
    "\n",
    "The issue suggests a partition at $t=7$. We will enforce this manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d07d812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Dataset:\n",
      "   time  event  x\n",
      "0     5      1  0\n",
      "1     8      0  1\n",
      "2    10      1  1\n"
     ]
    }
   ],
   "source": [
    "df_toy = pd.DataFrame({\n",
    "    'time': [5, 8, 10],\n",
    "    'event': [1, 0, 1], # 1=Event, 0=Censored\n",
    "    'x': [0, 1, 1]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"Toy Dataset:\")\n",
    "print(df_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7994",
   "metadata": {},
   "source": [
    " ### 2. Model Initialization\n",
    " We manually set `time_intervals` to `[0, 7, 11]` to match the example logic where $t=7$ is the cut point. (11 is just an upper bound > 10).\n",
    " * **Interval 1:** $0 \\le t < 7$ (Hazard $\\lambda_1$)\n",
    " * **Interval 2:** $7 \\le t < 11$ (Hazard $\\lambda_2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19207468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (4 chains in 1 job)\n",
      "NUTS: [beta, lambda0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\rich\\live.py:256: UserWarning: install \"ipywidgets\" for \n",
       "Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "error",
     "evalue": "(len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=7",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m model = BayesianPiecewiseCoxPH(time_intervals=cut_points)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_toy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mduration_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevent_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mevent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcores\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_accept\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\Documents\\IMTA\\4A\\PyBH\\PyBH\\SurvivalAnalysis\\cox.py:104\u001b[39m, in \u001b[36mBayesianPiecewiseCoxPH.fit\u001b[39m\u001b[34m(self, data, duration_col, event_col, draws, tune, chains, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, duration_col, event_col, draws=\u001b[32m2000\u001b[39m, tune=\u001b[32m1000\u001b[39m, chains=\u001b[32m4\u001b[39m, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28mself\u001b[39m._beta_means = \u001b[38;5;28mself\u001b[39m.idata.posterior[\u001b[33m\"\u001b[39m\u001b[33mbeta\u001b[39m\u001b[33m\"\u001b[39m].mean(dim=[\u001b[33m\"\u001b[39m\u001b[33mchain\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdraw\u001b[39m\u001b[33m\"\u001b[39m]).values\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m._lambda_means = \u001b[38;5;28mself\u001b[39m.idata.posterior[\u001b[33m\"\u001b[39m\u001b[33mlambda0\u001b[39m\u001b[33m\"\u001b[39m].mean(dim=[\u001b[33m\"\u001b[39m\u001b[33mchain\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdraw\u001b[39m\u001b[33m\"\u001b[39m]).values\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\Documents\\IMTA\\4A\\PyBH\\PyBH\\SurvivalAnalysis\\pymc_models.py:41\u001b[39m, in \u001b[36mBayesianSurvivalModel.fit\u001b[39m\u001b[34m(self, data, duration_col, event_col, draws, tune, chains, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 2. Run the MCMC sampler\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     \u001b[38;5;28mself\u001b[39m.idata = \u001b[43mpm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtune\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchains\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:951\u001b[39m, in \u001b[36msample\u001b[39m\u001b[34m(draws, tune, chains, cores, random_seed, progressbar, progressbar_theme, step, var_names, nuts_sampler, initvals, init, jitter_max_retries, n_init, trace, discard_tuned_samples, compute_convergence_checks, keep_warning_stat, return_inferencedata, idata_kwargs, nuts_sampler_kwargs, callback, mp_ctx, blas_cores, model, compile_kwargs, **kwargs)\u001b[39m\n\u001b[32m    949\u001b[39m         _print_step_hierarchy(step)\n\u001b[32m    950\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m joined_blas_limiter():\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m             \u001b[43m_sample_many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msample_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m t_sampling = time.time() - t_start\n\u001b[32m    955\u001b[39m \u001b[38;5;66;03m# Packaging, validating and returning the result was extracted\u001b[39;00m\n\u001b[32m    956\u001b[39m \u001b[38;5;66;03m# into a function to make it easier to test and refactor.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:1157\u001b[39m, in \u001b[36m_sample_many\u001b[39m\u001b[34m(draws, chains, traces, start, rngs, step, callback, **kwargs)\u001b[39m\n\u001b[32m   1155\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(chains):\n\u001b[32m   1156\u001b[39m         step.sampling_state = initial_step_state\n\u001b[32m-> \u001b[39m\u001b[32m1157\u001b[39m         \u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrngs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:1222\u001b[39m, in \u001b[36m_sample\u001b[39m\u001b[34m(chain, rng, start, draws, step, trace, tune, model, callback, progress_manager, **kwargs)\u001b[39m\n\u001b[32m   1210\u001b[39m sampling_gen = _iter_sample(\n\u001b[32m   1211\u001b[39m     draws=draws,\n\u001b[32m   1212\u001b[39m     step=step,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1219\u001b[39m     callback=callback,\n\u001b[32m   1220\u001b[39m )\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msampling_gen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchain_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_last\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtuning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mit\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[43mtune\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1227\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m progress_manager.combined_progress \u001b[38;5;129;01mor\u001b[39;00m chain == progress_manager.chains - \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\sampling\\mcmc.py:1294\u001b[39m, in \u001b[36m_iter_sample\u001b[39m\u001b[34m(draws, step, start, trace, chain, tune, rng, model, callback)\u001b[39m\n\u001b[32m   1291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == tune:\n\u001b[32m   1292\u001b[39m     step.stop_tuning()\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m point, stats = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m trace.record(point, stats)\n\u001b[32m   1296\u001b[39m log_warning_stats(stats)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\arraystep.py:116\u001b[39m, in \u001b[36mArrayStepShared.step\u001b[39m\u001b[34m(self, point)\u001b[39m\n\u001b[32m    113\u001b[39m     point = {name: point[name] \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.var_names}\n\u001b[32m    115\u001b[39m q = DictToArrayBijection.map(point)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m apoint, stats = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mastep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(apoint, RaveledVars):\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# We assume that the mapping has stayed the same\u001b[39;00m\n\u001b[32m    120\u001b[39m     apoint = RaveledVars(apoint, q.point_map_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\base_hmc.py:233\u001b[39m, in \u001b[36mBaseHMC.astep\u001b[39m\u001b[34m(self, q0)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._step_rand \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    231\u001b[39m     step_size = \u001b[38;5;28mself\u001b[39m._step_rand(step_size, rng=\u001b[38;5;28mself\u001b[39m.rng)\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m hmc_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_hamiltonian_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m perf_end = time.perf_counter()\n\u001b[32m    236\u001b[39m process_end = time.process_time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:217\u001b[39m, in \u001b[36mNUTS._hamiltonian_step\u001b[39m\u001b[34m(self, start, p0, step_size)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_treedepth):\n\u001b[32m    216\u001b[39m     direction = (rng.random() < \u001b[32m0.5\u001b[39m) * \u001b[32m2\u001b[39m - \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     divergence_info, turning = \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m divergence_info \u001b[38;5;129;01mor\u001b[39;00m turning:\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:357\u001b[39m, in \u001b[36m_Tree.extend\u001b[39m\u001b[34m(self, direction)\u001b[39m\n\u001b[32m    355\u001b[39m     \u001b[38;5;28mself\u001b[39m.right = tree.right\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     tree, diverging, turning = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_subtree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfloatX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     leftmost_begin, leftmost_end = tree.right, tree.left\n\u001b[32m    361\u001b[39m     rightmost_begin, rightmost_end = \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:445\u001b[39m, in \u001b[36m_Tree._build_subtree\u001b[39m\u001b[34m(self, left, depth, epsilon)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_build_subtree\u001b[39m(\u001b[38;5;28mself\u001b[39m, left, depth, epsilon):\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m depth == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_single_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m     tree1, diverging, turning = \u001b[38;5;28mself\u001b[39m._build_subtree(left, depth - \u001b[32m1\u001b[39m, epsilon)\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m diverging \u001b[38;5;129;01mor\u001b[39;00m turning:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\nuts.py:401\u001b[39m, in \u001b[36m_Tree._single_step\u001b[39m\u001b[34m(self, left, epsilon)\u001b[39m\n\u001b[32m    399\u001b[39m error_msg: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     right = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintegrator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m IntegrationError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    403\u001b[39m     error_msg = \u001b[38;5;28mstr\u001b[39m(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\integration.py:94\u001b[39m, in \u001b[36mCpuLeapfrogIntegrator.step\u001b[39m\u001b[34m(self, epsilon, state)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Leapfrog integrator step.\u001b[39;00m\n\u001b[32m     77\u001b[39m \n\u001b[32m     78\u001b[39m \u001b[33;03mHalf a momentum update, full position update, half momentum update.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     91\u001b[39m \u001b[33;03mNone if `out` is provided, else a State namedtuple\u001b[39;00m\n\u001b[32m     92\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m linalg.LinAlgError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     96\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mLinAlgError during leapfrog step.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ZBook\\anaconda3\\envs\\PyBH\\Lib\\site-packages\\pymc\\step_methods\\hmc\\integration.py:120\u001b[39m, in \u001b[36mCpuLeapfrogIntegrator._step\u001b[39m\u001b[34m(self, epsilon, state)\u001b[39m\n\u001b[32m    116\u001b[39m dt = \u001b[32m0.5\u001b[39m * epsilon\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# p is already stored in p_new\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# p_new = p + dt * q_grad\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43maxpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mq_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m pot.velocity(p_new, out=v_new)\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# q is already stored in q_new\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# q_new = q + epsilon * v_new\u001b[39;00m\n",
      "\u001b[31merror\u001b[39m: (len(y)-offy>(n-1)*abs(incy)) failed for 1st keyword n: daxpy:n=7"
     ]
    }
   ],
   "source": [
    "# We manually define the cut-points (including 0 and something > max time)\n",
    "cut_points = [0, 7, 11]   # 11 > max observed time\n",
    "\n",
    "model = BayesianPiecewiseCoxPH(time_intervals=cut_points)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    data=df_toy,\n",
    "    duration_col='time',\n",
    "    event_col='event',\n",
    "    draws=2000,\n",
    "    tune=1000,\n",
    "    chains=4,\n",
    "    cores=1,\n",
    "    target_accept=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fd58b",
   "metadata": {},
   "source": [
    " ### 3. Diagnostics & Summary\n",
    " We verify that we estimated $\\beta$, $\\lambda_0$ (first interval), and $\\lambda_1$ (second interval)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee5ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of posterior\n",
    "print(az.summary(model.idata, var_names=['beta', 'lambda0'], round_to=4))\n",
    "\n",
    "# Trace plot (very useful with so few observations!)\n",
    "az.plot_trace(model.idata, var_names=['beta', 'lambda0'], compact=True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check R-hat and ESS\n",
    "print(\"\\nDiagnostics:\")\n",
    "print(az.summary(model.idata, var_names=['beta', 'lambda0'])[['r_hat', 'ess_bulk', 'ess_tail']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599de8b",
   "metadata": {},
   "source": [
    "### 4. Verify Data Expansion logic\n",
    "Internally, the class converts the 3 rows into 5 rows (based on the splits).\n",
    "* **Subj 1:** (0-5, Event) -> Interval 0\n",
    "* **Subj 2:** (0-7, No Event) -> Interval 0\n",
    "* **Subj 2:** (7-8, Censored) -> Interval 1\n",
    "* **Subj 3:** (0-7, No Event) -> Interval 0\n",
    "* **Subj 3:** (7-10, Event) -> Interval 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a0a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare prediction grid\n",
    "X_new = pd.DataFrame({\n",
    "    'x': [0, 1]           # one curve for x=0, one for x=1\n",
    "})\n",
    "\n",
    "# Predict survival functions\n",
    "surv_df = model.predict_survival_function(X_new, times=np.linspace(0, 10.5, 200))\n",
    "\n",
    "# Rename columns for clarity\n",
    "surv_df.columns = ['x = 0', 'x = 1']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for col in surv_df.columns:\n",
    "    plt.step(surv_df.index, surv_df[col], where='post', label=col, lw=2.2)\n",
    "\n",
    "# Add observed events/censorings\n",
    "plt.plot(5,  surv_df.loc[5, 'x = 0'],  'o', ms=10, color='C0', alpha=0.8, label='Event x=0')\n",
    "plt.plot(8,  surv_df.loc[8, 'x = 1'],  'x', ms=12, mew=3, color='C1', label='Censored x=1')\n",
    "plt.plot(10, surv_df.loc[10, 'x = 1'], 'o', ms=10, color='C1', alpha=0.8, label='Event x=1')\n",
    "\n",
    "plt.title('Estimated Survival Functions â€“ Piecewise Constant Cox PH', fontsize=13)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.ylabel('Survival Probability S(t)', fontsize=12)\n",
    "plt.legend(fontsize=11)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xlim(0, 11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f9356d",
   "metadata": {},
   "source": [
    "### 5. Prediction\n",
    "Predicting survival curves for $x=0$ and $x=1$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyBH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
